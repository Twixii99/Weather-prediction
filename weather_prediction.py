# -*- coding: utf-8 -*-
"""Weather prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BVLQFp7-8Wpn07qD8w6kOg-sgf6wthOn

# 1. Kaggle authentaction API and getting the Dataset
"""

! pip install kaggle

! mkdir ~/.kaggle

! cp kaggle.json ~/.kaggle

! chmod 600 ~/.kaggle/kaggle.json

! kaggle datasets download jsphyg/weather-dataset-rattle-package

! unzip weather-dataset-rattle-package.zip

"""# 2. Impot the used libraries"""

! pip install xgboost

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import warnings

warnings.filterwarnings('ignore')
# %matplotlib inline

from IPython.display import display
from sklearn.metrics import mutual_info_score, accuracy_score, roc_auc_score, precision_score, recall_score
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction import DictVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.ensemble import RandomForestClassifier
import xgboost as xgb


import pickle

"""# 3.  Loading the Dataset """

df = pd.read_csv('weatherAUS.csv')
df.head()

# The Date column is meaningless for analysis.
del df['Date']

len(df), len(df.columns)

"""# 4. Data Cleaning """

df.columns

df.columns = df.columns.str.lower()
df.head()

df.dtypes

categorical_variables = ['location',
  'windgustdir',
  'winddir9am',
  'winddir3pm',
  'raintoday']

numerical_variables = ['mintemp',
  'maxtemp',
  'rainfall',
  'evaporation',
  'sunshine',
  'windgustspeed',
  'windspeed9am',
  'windspeed3pm',
  'humidity9am',
  'humidity3pm',
  'pressure9am',
  'pressure3pm',
  'cloud9am',
  'cloud3pm',
  'temp9am',
  'temp3pm']

for col in categorical_variables:
  df[col] = df[col].str.lower()

"""# 5. EDA

## 5.0 The target variable analysis
"""

df.isnull().sum()

df['raintomorrow'].unique()

df = df.drop(df[df.raintomorrow.isnull()].index)
df = df.reset_index(drop=True)

df.isnull().sum()

df['raintomorrow'].unique()

sns.countplot(x='raintomorrow', data=df)

df['raintomorrow'] = (df['raintomorrow'] == 'Yes').astype(int)

"""## 5.1 Categorical feature analysis

### 5.1.1 Dealing with the missing values
"""

df[categorical_variables]

for col in categorical_variables:
  df[col] = df.groupby(df['raintomorrow'])[col].apply(lambda f: f.fillna(f.mode().values[0]))

df[categorical_variables].isnull().sum()

df['raintoday'] = (df['raintoday'] == 'yes').astype(int).astype(str)
df['raintoday'].value_counts()

"""### 5.1.2 Depandancy analysis"""

mi = df[categorical_variables].apply(lambda a: mutual_info_score(a, df['raintomorrow']))
mi.sort_values(ascending=False)

"""## 5.1 Numerical feature analysis

### 5.1.1 Univariate analysis
"""

df[numerical_variables].describe()

pd.plotting.hist_frame(df[numerical_variables], figsize=(15,15), bins=50, layout=(4, 4));

df[numerical_variables].isnull().sum()

uniformally_distributed_variables = ['mintemp', 'maxtemp', 
                                     'sunshine', 'windgustspeed', 
                                     'windspeed3pm', 'humidity9am', 
                                     'humidity3pm', 'pressure9am',
                                     'pressure3pm', 'temp9am', 
                                     'temp3pm'
                                     ]
for col in uniformally_distributed_variables:
  df[col] = df.groupby(df['raintomorrow'])[col].apply(lambda f: f.fillna(f.mean()))

df[numerical_variables].isnull().sum()

"""#### More Checking the other numerical variables distributions"""

sns.histplot(df.evaporation[df.evaporation < 40], bins=100)
plt.show()
sns.histplot(df.windspeed9am, bins=50)
plt.show()
sns.histplot(df.rainfall[df.rainfall < 10], bins=100);

right_skewed_distributed_variables = ['rainfall', 'evaporation', 'windspeed9am', 'cloud9am', 'cloud3pm']

for col in right_skewed_distributed_variables:
  df[col] = df.groupby(df['raintomorrow'])[col].apply(lambda f: f.fillna(f.median()))

df[numerical_variables].isnull().sum()

"""### 5.1.2 Bivariate analysis"""

fig, ax = plt.subplots(figsize=(15,10)) 
sns.heatmap(df[numerical_variables].corr(), annot=True, ax=ax)

pd.plotting.scatter_matrix(df[numerical_variables], figsize=(30, 30));

"""# 6. Model Trainings

## 6.1 Train, Validation, Test datasets extraction
"""

full_train, test = train_test_split(df, test_size=0.2, shuffle=True, random_state=11)
train, validation = train_test_split(full_train, test_size=0.25, shuffle=True, random_state=11)

len(df), len(train), len(validation), len(test)

train = train.reset_index(drop=True)
validation = validation.reset_index(drop=True)
test = test.reset_index(drop=True)
full_train = full_train.reset_index(drop=True)

y_train = train['raintomorrow'].values
y_val = validation['raintomorrow'].values
y_test = test['raintomorrow'].values
y_full_train = full_train['raintomorrow'].values

del train['raintomorrow']
del validation['raintomorrow']
del test['raintomorrow']
del full_train['raintomorrow']

"""## 6.2 One-hot encoding"""

dv = DictVectorizer(sparse=False)

X_train = dv.fit_transform(train.to_dict(orient='records'))
X_val = dv.transform(validation.to_dict(orient='records'))

dv2 = DictVectorizer(sparse=False)

X_full_train = dv2.fit_transform(full_train.to_dict(orient='records'))
X_test = dv2.transform(test.to_dict(orient='records'))

len(dv.get_feature_names()), len(dv.get_feature_names())

"""## 6.3 Logistic Regression Model"""

evaluation_metrics = pd.DataFrame({'Logistic_Regression_val': [0,0,0,0], 'Decision_Tree_val': [0,0,0,0], 'Random_Forest_val': [0,0,0,0], 
                                   'Logistic_Regression_test': [0,0,0,0], 'Decision_Tree_test': [0,0,0,0], 'Random_Forest_test': [0,0,0,0]}, 
                                  dtype=np.float64,
                                  index=['Accurecy', 'Precision', 'Recall', 'ROC_AUC'])

def add_record_val(y_pred, where):
  evaluation_metrics.loc['Accurecy', where] = accuracy_score(y_val, y_pred >= 0.5)
  evaluation_metrics.loc['ROC_AUC', where] = roc_auc_score(y_val, y_pred)
  evaluation_metrics.loc['Precision', where] = precision_score(y_val, y_pred >= 0.5)
  evaluation_metrics.loc['Recall', where] = recall_score(y_val, y_pred >= 0.5)

def add_record_test(y_pred_test, where):
  evaluation_metrics.loc['Accurecy', where] = accuracy_score(y_test, y_pred_test >= 0.5)
  evaluation_metrics.loc['ROC_AUC', where] = roc_auc_score(y_test, y_pred_test)
  evaluation_metrics.loc['Precision', where] = precision_score(y_test, y_pred_test >= 0.5)
  evaluation_metrics.loc['Recall', where] = recall_score(y_test, y_pred_test >= 0.5)

"""### 6.3.1 Training and Validating the model"""

lr_model = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=11)
lr_model.fit(X_train, y_train)

y_pred = lr_model.predict_proba(X_val)[:, 1]

add_record_val(y_pred, 'Logistic_Regression_val')

"""### 6.3.2 Testing the model"""

lr_model_test = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=11)
lr_model_test.fit(X_full_train, y_full_train)

y_pred_test = lr_model_test.predict_proba(X_test)[:, 1]

add_record_test(y_pred_test, 'Logistic_Regression_test')

evaluation_metrics

"""## 6.4 Decision Tree

### 6.4.1 Training and Validating the Model
"""

dt_model = DecisionTreeClassifier(random_state=11)
dt_model.fit(X_train, y_train)

y_pred = dt_model.predict_proba(X_val)[:, 1]

roc_auc_score(y_val, y_pred)

"""### 6.4.2 Parameters Tunning"""

depths = [1, 2, 3, 4, 5, 6, 10, 15, 20, 40, 80, 100, None]

for depth in depths: 
    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=11)
    dt_model.fit(X_train, y_train)
    
    y_pred = dt_model.predict_proba(X_val)[:, 1]
    auc = roc_auc_score(y_val, y_pred)
    
    print('%4s -> %.5f' % (depth, auc))

scores = []

for depth in [3, 4, 5, 6, 10]:
    for s in [1, 5, 10, 15, 20, 500, 100, 200]:
        dt_model = DecisionTreeClassifier(max_depth=depth, min_samples_leaf=s, random_state=11)
        dt_model.fit(X_train, y_train)

        y_pred = dt_model.predict_proba(X_val)[:, 1]
        auc = roc_auc_score(y_val, y_pred)
        
        scores.append((depth, s, auc))

aggregation_results = pd.DataFrame(data=scores, columns=['depth', 'minmum_leaf_samples', 'ROC_AUC'])
aggregation_results

pivot_table = aggregation_results.pivot(index='depth', columns=['minmum_leaf_samples'], values=['ROC_AUC'])

fig, ax = plt.subplots(figsize=(15,10)) 
sns.heatmap(pivot_table, annot=True, ax=ax)

dt_model = DecisionTreeClassifier(max_depth=10, min_samples_leaf=100)
dt_model.fit(X_train, y_train)

y_pred = dt_model.predict_proba(X_val)[:, 1]

add_record_val(y_pred, 'Decision_Tree_val')

"""### 6.4.3 Testing The model"""

dt_model_test = DecisionTreeClassifier(max_depth=10, min_samples_leaf=100, random_state=11)
dt_model_test.fit(X_full_train, y_full_train)

y_pred_test = dt_model_test.predict_proba(X_test)[:, 1]

add_record_test(y_pred_test, 'Decision_Tree_test')

evaluation_metrics

"""## 6.5 Random Forest Model

### 6.5.1 Training and Validating the Model
"""

rf_model = RandomForestClassifier(n_estimators=50, random_state=11)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict_proba(X_val)[:, 1]
y_pred

roc_auc_score(y_val, y_pred)

"""### 6.5.2 Parameters Tunning"""

scores = []

for n in range(10, 201, 10):
    rf_model = RandomForestClassifier(n_estimators=n, random_state=11)
    rf_model.fit(X_train, y_train)

    y_pred = rf_model.predict_proba(X_val)[:, 1]
    auc = roc_auc_score(y_val, y_pred)
    
    scores.append((n, auc))

df_scores = pd.DataFrame(scores, columns=['n_estimators', 'auc'])

plt.plot(df_scores.n_estimators, df_scores.auc)

scores = []

for d in [5, 10, 15]:
    for n in range(10, 201, 10):
        rf_model = RandomForestClassifier(n_estimators=n,
                                    max_depth=d,
                                    random_state=11)
        rf_model.fit(X_train, y_train)

        y_pred = rf_model.predict_proba(X_val)[:, 1]
        auc = roc_auc_score(y_val, y_pred)

        scores.append((d, n, auc))

columns = ['max_depth', 'n_estimators', 'auc']
df_scores_tunning = pd.DataFrame(scores, columns=columns)
df_scores_tunning

for d in [5, 10, 15]:
    df_subset = df_scores_tunning[df_scores_tunning.max_depth == d]
    
    plt.plot(df_subset.n_estimators, df_subset.auc,
             label='max_depth=%d' % d)

plt.legend()

scores = []

for s in [1, 3, 5, 10, 50]:
    for n in range(10, 201, 10):
        rf_model = RandomForestClassifier(n_estimators=n,
                                    max_depth=15,
                                    min_samples_leaf=s,
                                    random_state=11)
        rf_model.fit(X_train, y_train)

        y_pred = rf_model.predict_proba(X_val)[:, 1]
        auc = roc_auc_score(y_val, y_pred)

        scores.append((s, n, auc))

columns = ['min_samples_leaf', 'n_estimators', 'auc']
df_scores_tunning2 = pd.DataFrame(scores, columns=columns)

colors = ['black', 'blue', 'orange', 'red', 'grey']
values = [1, 3, 5, 10, 50]

for s, col in zip(values, colors):
    df_subset = df_scores_tunning2[df_scores_tunning2.min_samples_leaf == s]
    
    plt.plot(df_subset.n_estimators, df_subset.auc,
             color=col,
             label='min_samples_leaf=%d' % s)

plt.legend()

rf_model = RandomForestClassifier(n_estimators=200, 
                                 max_depth=15,
                                 min_samples_leaf=1,
                                 random_state=11)
rf_model.fit(X_train, y_train)

y_pred = rf_model.predict_proba(X_val)[:, 1]

add_record_val(y_pred, 'Random_Forest_val')

"""### 6.5.3 Testing the Model"""

rf_model_test = RandomForestClassifier(n_estimators=200, 
                                 max_depth=15,
                                 min_samples_leaf=1,
                                 random_state=11)
rf_model_test.fit(X_full_train, y_full_train)

y_pred_test = rf_model_test.predict_proba(X_test)[:, 1]

add_record_test(y_pred_test, 'Random_Forest_test')

evaluation_metrics

"""# 6.6 XGBoosting"""

D_train = xgb.DMatrix(X_train, label=y_train, feature_names=dv.get_feature_names())
D_val = xgb.DMatrix(X_val, label=y_val, feature_names=dv.get_feature_names())
D_full_train = xgb.DMatrix(X_full_train, label=y_full_train, feature_names=dv2.get_feature_names())
D_test = xgb.DMatrix(X_test, label=y_test, feature_names=dv2.get_feature_names())

xgb_params = {
    'eta': 0.3, 
    'max_depth': 6,
    'min_child_weight': 1,
    
    'objective': 'binary:logistic',
    'nthread': 8,
    
    'seed': 1,
    'verbosity': 1,
}

xgb_model = xgb.train(xgb_params, D_train, num_boost_round=100)

y_pred = xgb_model.predict(D_val)

roc_auc_score(y_val, y_pred)

xgb_model_test = xgb.train(xgb_params, D_full_train, num_boost_round=100)

y_pred_test = xgb_model_test.predict(D_test)

roc_auc_score(y_test, y_pred_test)

add_record_val(y_pred, 'XGBoosting_val')
add_record_test(y_pred_test, 'XGBoosting_test')

evaluation_metrics = evaluation_metrics[['Logistic_Regression_val',
 'Decision_Tree_val',
 'Random_Forest_val',
 'XGBoosting_val',
 'Logistic_Regression_test',
 'Decision_Tree_test',
 'Random_Forest_test',
 'XGBoosting_test']]

evaluation_metrics

"""# 7. Model Saving and Loading"""

model_name = 'xgb_model'
model_file = f'model_{model_name}.bin'

with open(model_file, 'wb') as m_out:
  pickle.dump(xgb_model_test, m_out)

with open(model_file, 'rb') as m_out:
  loaded_model = pickle.load(m_out)

dd = xgb.DMatrix(np.array([list(X_train[1000])]), label=[y_train[1000]], feature_names=dv.get_feature_names())

loaded_model.predict(dd)[0]

